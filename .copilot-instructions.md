# JARVIX Copilot Instructions

## Project Overview
JARVIX is an **Intelligence Factory** - transforms URLs/competitors/niches into actionable business opportunities.

**Stack**: Rust 1.92 (tokio async) + Julia 1.12 (scoring) + TypeScript 5.9 (reports) + PowerShell 7 (orchestration)

## Architecture
```
URLs → Collect (Rust async) → Curate (policy gate) → Score (Julia ponderado) → Report (TypeScript/HTML) → Actions (Phase 1)
```

## Phase Status
- **Phase 1 (Julia)**: Actions engine - BUY/MONITOR/SKIP decisions
- **Phase 2 (Rust)**: Auto-discovery - Maigret + SpiderFoot
- **Phase 3 (Julia)**: Temporal trends - WoW analysis
- **Phase 4 (TypeScript)**: PDF export - PDFKit + Chart.js
- **Phase 5 (Rust)**: API enrichment - Google Trends, Shopify, Crunchbase
- **Phase 6 (Rust)**: Scalability - tokio workers, Parquet, Distributed.jl

## Code Structure
```
engine/             # Rust CLI + async collection
├── src/
│   ├── main.rs    # CLI (migrate, collect, curate commands)
│   ├── db.rs      # SQLite EventLogger (7 columns, 3 indices)
│   ├── collector.rs # tokio async downloader (HTML parser)
│   └── policy.rs  # Domain/path/paywall validation
science/           # Julia algorithms
├── score.jl       # Scoring: 40% quality + 30% buy + 20% text - 10% errors
└── [actions.jl, trends.jl, parallel_score.jl] # Coming in phases
app/               # TypeScript/Node reports
├── report.ts      # HTML dashboard generator
└── [pdf.ts, batch.ts] # Coming in phases
scripts/           # PowerShell orchestration
├── run_mvp.ps1    # Full pipeline runner
└── build.ps1      # Cargo compiler
data/              # Configuration + outputs
├── seeds.txt      # Input URLs (5 examples)
├── allowed_domains.txt # Whitelist (6 domains)
├── paywall_keywords.txt # Paywall detector (14 keywords)
├── jarvix.db      # SQLite (events table)
└── reports/, scores/ # Output directories
```

## Key Data Structures

### events table (SQLite)
```sql
id, run_id, event_type, url, status, details, timestamp
```

### Score format (JSONL)
```json
{
  "url": "example.com",
  "score": 58.0,
  "quality": 85,
  "buy_keywords": 2,
  "text_length": 1250,
  "errors": 0
}
```

### Action format (Phase 1)
```json
{
  "url": "example.com",
  "score": 58.0,
  "action": "MONITOR",
  "confidence": 0.70,
  "reason": "Evaluate competence for 30 days"
}
```

## Important Conventions

### Julia
- Always use `JSON.parse()`, `JSON.write()` for serialization
- Scoring function: `ponderado = 0.4*q + 0.3*b + 0.2*t - 0.1*e`
- Output format: JSONL one record per line
- Dependencies: JSON, Statistics packages

### Rust
- Use `tokio::spawn_blocking` for I/O-heavy operations
- Async download: `reqwest` with 15s timeout
- Error handling: Return `Result<T, String>` for clarity
- CLI parsing: Use `clap` derive macros

### TypeScript
- HTML generation: Return string template literals
- JSON parsing: Always use `as const` for type safety
- Async/await for file I/O

### PowerShell
- Escape special chars: Use backticks for $ in shell commands
- Error handling: Check exit codes with `$LASTEXITCODE`
- Logging: Use `Write-Host` for status messages

## Before Starting a Phase

1. Read the full GitHub issue for that phase
2. Check existing code patterns in `engine/`, `science/`, `app/`
3. Verify output format matches integration expectations
4. Add unit tests (200+ records)
5. Ensure error handling with graceful fallbacks

## Testing Commands

```bash
# Build
cd engine && cargo build --release

# Full pipeline
.\scripts\run_mvp.ps1

# Individual modules
julia science/score.jl
npx ts-node app/report.ts <run_id>
```

## Integration Points

- **Phase 1 → v1.0**: `science/actions.jl` must read v1.0 scores JSONL, output actions JSONL
- **Phase 2 → Phase 1**: `engine/src/discovery.rs` generates seeds.txt → collector
- **Phase 4 → v1.0**: `app/pdf.ts` reads data/scores/*.jsonl and data/top/*.json
- **Phase 5 → Phase 1**: `engine/src/enrichment.rs` modifies scores before actions

## Performance Targets

| Phase | Metric | Target |
|-------|--------|--------|
| Phase 1 | 100 records | < 5s |
| Phase 2 | 1000 URLs | < 5min |
| Phase 3 | 1000 records | < 2min |
| Phase 4 | 100 records → PDF | < 5s |
| Phase 5 | 100 enrichments | < 30s |
| Phase 6 | 10,000 URLs | < 5min |

## Success Criteria

All phases must:
- [ ] Pass unit tests (100+ test cases)
- [ ] Integrate seamlessly with existing pipeline
- [ ] Handle errors gracefully (no panic/crash)
- [ ] Output reproducible results
- [ ] Meet performance targets
- [ ] Have clear code comments

**MINIMAL DOCS - Only this file is needed for context.**
